{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original data set: 8282\n",
      "Number of removed names: 5832\n",
      "Finished 'remove_duplicates' in  0.0051 secs\n"
     ]
    }
   ],
   "source": [
    "import json # Used to load data set\n",
    "import functools # Used to maintain introspection on decorators\n",
    "import time # Used to time functions\n",
    "\n",
    "# Tested but not needed in final\n",
    "#import numpy as np # Used for the .unique() to remove dulpicates\n",
    "#import pandas as pd # Used for series\n",
    "#from collections import OrderedDict\n",
    "\n",
    "def functionTimer(func):\n",
    "    \"\"\"Prints the functions runtime\"\"\"\n",
    "    @functools.wraps(func) # maintains introspection\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        runtime = end - start\n",
    "        print (f\"Finished {func.__name__!r} in {runtime: .4f} secs\")\n",
    "        #return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@functionTimer\n",
    "def remove_duplicates():\n",
    "    '''\n",
    "    Does Somthing.\n",
    "    \n",
    "        Parameters:\n",
    "        \n",
    "        Returns:\n",
    "    '''\n",
    "    # Load data O(n)\n",
    "    with open('org_names.json', mode='r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    original_size = len(data) # To use as a comparison\n",
    "    print(\"Size of original data set:\", original_size)\n",
    "\n",
    "    clean_data1 = []\n",
    "    clean_data2 =[]\n",
    "\n",
    "    # Converts each string to lowercase\n",
    "    for i in data:\n",
    "        clean_data1.append(i.lower()) # Removes 75\n",
    "        \n",
    "    # Convert list to a dictionary then back to a list to automatically remove identical items\n",
    "    clean_data2 = list(dict.fromkeys(clean_data1)) # Removes 5757\n",
    "    \n",
    "    final_size = len(clean_data2) # To use as a comparison\n",
    "    print(\"Number of removed names:\", original_size - final_size)\n",
    "\n",
    "remove_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools # used to maintain introspection on decorators\n",
    "import time # used to time functions\n",
    "\n",
    "def functionTimer(func):\n",
    "    \"\"\"Prints the functions runtime\"\"\"\n",
    "    @functools.wraps(func) # maintains introspection\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        runtime = end - start\n",
    "        print (f\"Finished {func.__name__!r} in {runtime: .4f} secs\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Complexity = O(n)\n",
    "\n",
    "Read json file = O(n)\n",
    ".len() = O(n)\n",
    "For loop = O(n)\n",
    ".append() = O(n)\n",
    "Converting to dictionary = O(n)\n",
    "Converting back to a list = O(n)\n",
    ".len() = O(n)\n",
    "\n",
    "O is worst case senario\n",
    "Ω is best case senario\n",
    "Θ is the middle ground\n",
    "\n",
    "TESTING/RESULTS\n",
    "\n",
    "Convert list to a dictionary then back to a list to automatically remove identical items\n",
    "data = list(dict.fromkeys(data)) \n",
    "In 0.0060, 0.0057, 0.0042\n",
    "Average = 0.0043\n",
    "\n",
    "Convert list to a set then back to a list to automatically remove identical items\n",
    "data = list(set(data))\n",
    "In 0.0072, 0.0079, 0.0048\n",
    "Average = 0.0054\n",
    "\n",
    "Convert list to a dictionary then back to a list using the collections moduel \n",
    "data = list(OrderedDict.fromkeys(data)) \n",
    "In 0.0057, 0.0078, 0.0088\n",
    "Average = 0.0059\n",
    "\n",
    "Convert a list to a Numpy array to remove duplicates using .unique()\n",
    "data = np.unique(np.array(data)).tolist()\n",
    "In 0.0321, 0.0283, 0.0308\n",
    "Average = 0.0250\n",
    "\n",
    "Use a numpy array and a pandas series\n",
    "clean_data2 = pd.Series(clean_data1).unique().tolist()\n",
    "in 0.0192, 0.009, 0.0076\n",
    "Average = 0.0076\n",
    "\n",
    "Replacing strings with lowercase removed 75 items but reduced function speed by 0.0035 from 0.0043, \n",
    "Average = 0.0075\n",
    "\n",
    "Removed the word 'limitied' from all items before removal but didnt impact removal count\n",
    "for i in clean_data1:\n",
    "    remove_limited = i.replace(\"limited\", \"\")\n",
    "    clean_data2.append(remove_limited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK\n",
    "Background: Every time one of our users runs a report our Search & NLP pipeline fetches loads of information about them from company records, news articles, and blog posts. After completing this it will be able to generate a list of all company names it’s seen, we want to deduplicate entries in this list, so that our Report Generation pipeline can group together information about the same company before displaying it to the user.\n",
    "Task: Write a function which takes in a list of company/organisation names, and reduces the list to one entry per company. Lots of companies will be in their multiple times, possibly with different forms of their names. The file provided should be treated as a representative example of the list of names your function will receive. You should carefully consider the time complexity of your code.\n",
    "Include unit tests to show that your function works on various edge cases. The problem is fairly ill-defined and open ended, so part of the challenge is to define some bounds for your work! We're not looking for a complete solution - just a decent stab, a few good ideas and some sensible code.\n",
    "Feel free to import and use any libraries or external datasets you like - that's a key part of real-world software development.\n",
    "You should take care to ensure your code is readable and well-commented where necessary. Share your code (the whole solution, including the tests) with us (zip in an email, or public GitHub project). Please also share with us any additional comments, thoughts, or ideas about any difficulties you encountered in this task, and please take care to explain any limitations of your solution which you're aware of.\n",
    "\n",
    "STEPS\n",
    "- Write a function\n",
    "- Function takes in a list\n",
    "- Reduce the list to 1 entry per company\n",
    "- Consider time complexity\n",
    "- Unit tests prooving it deals with edge cases\n",
    "- Readable and well commented\n",
    "- Share ideas and difficulties\n",
    "- Explain limitations\n",
    "\n",
    "IDEAS\n",
    "Use a set or dictionary to remove duplicates automatically\n",
    "Store the size of the list to compare after cleaning to see how many duplicates were removed\n",
    "Use a decorator to time the function\n",
    "Use wildcards to remove unnecessary words\n",
    "Remove obvious words (without editing them) like 'LIMITED' and 'LTD'\n",
    "Do as few cycles of the list as possible to maintain speed\n",
    "Refactor funtion into smaller functions?\n",
    "Rewrite function timer to take an average of 3\n",
    "\n",
    "QUESTIONS\n",
    "Is transfering to a set less speedy than transfering to a dictionary?\n",
    "Is there a method for removing duplicates? (Pandas? NumPy?)\n",
    "Test a random section instead of the whole document to reduce time?\n",
    "Would a generator be useful?\n",
    "Would RegEx be useful?\n",
    "Some of the items are in caps, does case matter?\n",
    "\n",
    "ANSWERS\n",
    "A set is slower than a dictionary\n",
    "Theres an out of data library (precurser to dictionaries) that creates a dictionary. Called collections. This is slower that both sets and dictionaries\n",
    "Numpy has a .unique() method but converting it to an array and back was exceptionally slow\n",
    "Using a pandas series was faster than NumPy but not as fast as the in-built options\n",
    "All 4 data structures removed 5757 items. This consistancy shows they are working in the same way\n",
    "Looping through a for loop to check each item would be slow\n",
    "Some leetcode answers suggest using pointers but leetcode isnt always the more practle in real life situations\n",
    "Python lists are case sensitive, use lower() to convert all to lowercase. This removed 75 more items but reduced speed by an average of 0.0032\n",
    "Removed the word 'limited' from the items in an effort to remove more items but had no effect so code was removed\n",
    "Due to the above reason it is unlikely that the use of wildcards would have an impact either\n",
    "Using a RegEx (regular expressions) could be an option but I would have to know what to look for and so was not used\n",
    "Function only iterates once so a generator isnt necessary \n",
    "\n",
    "LIMITATIONS/EXTRAS\n",
    "Doesnt actually check if the in-built methods are removing the same items, just assumes because they are removing the same amount\n",
    "Could use a regex to find the most common letter pattens, then manually decide if that word is necessary, then remove that word from the data set\n",
    "Could automate the above process?^\n",
    "\n",
    "\n",
    "RESOURCES USED\n",
    "https://www.w3schools.com/python/python_howto_remove_duplicates.asp\n",
    "https://datagy.io/python-remove-duplicates-from-list/\n",
    "https://www.programiz.com/python-programming/methods/string/casefold\n",
    "https://www.geeksforgeeks.org/complexity-cheat-sheet-for-python-operations/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2323210cb3c8fce07363cf92901cad3c816f4700461b1042c93c6f5411008d5b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
