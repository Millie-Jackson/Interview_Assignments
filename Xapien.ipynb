{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original data set: 8282\n",
      "Number of removed names: 5832\n",
      "Finished 'remove_duplicates' in  0.0097 secs\n",
      "Size of original data set: 8282\n",
      "Number of removed names: 5832\n"
     ]
    }
   ],
   "source": [
    "import json # Used to loan data set\n",
    "import functools # Used to maintain introspection on decorators\n",
    "import time # Used to time functions\n",
    "import numpy as np # Used for the .unique() to remove dulpicates\n",
    "#import pandas as pd # Used for series\n",
    "\n",
    "#from collections import OrderedDict\n",
    "\n",
    "def functionTimer(func):\n",
    "    \"\"\"Prints the functions runtime\"\"\"\n",
    "    @functools.wraps(func) # maintains introspection\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        runtime = end - start\n",
    "        print (f\"Finished {func.__name__!r} in {runtime: .4f} secs\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@functionTimer\n",
    "def remove_duplicates():\n",
    "    '''\n",
    "    Does Somthing.\n",
    "    \n",
    "        Parameters:\n",
    "        \n",
    "        Returns:\n",
    "    '''\n",
    "    # Load data\n",
    "    with open('org_names.json', mode='r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    original_size = len(data) # To use as a comparison\n",
    "    print(\"Size of original data set:\", original_size)\n",
    "\n",
    "    # converts each string to lowercase\n",
    "    # Removes 75\n",
    "    clean_data = []\n",
    "\n",
    "    for i in data:\n",
    "        lower = i.lower()\n",
    "        clean_data.append(lower)\n",
    "\n",
    "    # Convert list to a dictionary then back to a list to automatically remove identical items\n",
    "    clean_data = list(dict.fromkeys(clean_data)) # Removes 5757\n",
    "\n",
    "\n",
    "    # Use a numpy array and a pandas series\n",
    "    #clean_data = pd.Series(clean_data).unique().tolist()\n",
    "    \n",
    "    final_size = len(clean_data) # To use as a comparison\n",
    "    print(\"Number of removed names:\", original_size - final_size)\n",
    "    #print(data)\n",
    "\n",
    "remove_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools # used to maintain introspection on decorators\n",
    "import time # used to time functions\n",
    "\n",
    "def functionTimer(func):\n",
    "    \"\"\"Prints the functions runtime\"\"\"\n",
    "    @functools.wraps(func) # maintains introspection\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        runtime = end - start\n",
    "        print (f\"Finished {func.__name__!r} in {runtime: .4f} secs\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert list to a dictionary then back to a list to automatically remove identical items\n",
    "data = list(dict.fromkeys(data)) \n",
    "# Removes 5757 \n",
    "# In 0.0060\n",
    "# In 0.0057\n",
    "# In 0.0042\n",
    "# Average = 0.0043\n",
    "\n",
    "# Convert list to a set then back to a list to automatically remove identical items\n",
    "data = list(set(data))\n",
    "# Removes 5757 \n",
    "# In 0.0072\n",
    "# In 0.0079\n",
    "# In 0.0048\n",
    "# Average = 0.0054\n",
    "\n",
    "# Convert list to a dictionary then back to a list using the collections moduel \n",
    "data = list(OrderedDict.fromkeys(data))\n",
    "# Removes 5757 \n",
    "# In 0.0057\n",
    "# In 0.0078\n",
    "# In 0.0088\n",
    "# Average = 0.0059\n",
    "\n",
    "# Convert a list to a Numpy array to remove duplicates using .unique()\n",
    "data = np.unique(np.array(data)).tolist()\n",
    "# Removes 5757 \n",
    "# In 0.0321\n",
    "# In 0.0283\n",
    "# In 0.0308\n",
    "# Average = 0.0250\n",
    "\n",
    "# Eeplacing strings with lowercase removed 75 items but reduced function speed by 0.0035 from 0.0043, \n",
    "# Average = 0.0075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK\n",
    "Background: Every time one of our users runs a report our Search & NLP pipeline fetches loads of information about them from company records, news articles, and blog posts. After completing this it will be able to generate a list of all company names itâ€™s seen, we want to deduplicate entries in this list, so that our Report Generation pipeline can group together information about the same company before displaying it to the user.\n",
    "Task: Write a function which takes in a list of company/organisation names, and reduces the list to one entry per company. Lots of companies will be in their multiple times, possibly with different forms of their names. The file provided should be treated as a representative example of the list of names your function will receive. You should carefully consider the time complexity of your code.\n",
    "Include unit tests to show that your function works on various edge cases. The problem is fairly ill-defined and open ended, so part of the challenge is to define some bounds for your work! We're not looking for a complete solution - just a decent stab, a few good ideas and some sensible code.\n",
    "Feel free to import and use any libraries or external datasets you like - that's a key part of real-world software development.\n",
    "You should take care to ensure your code is readable and well-commented where necessary. Share your code (the whole solution, including the tests) with us (zip in an email, or public GitHub project). Please also share with us any additional comments, thoughts, or ideas about any difficulties you encountered in this task, and please take care to explain any limitations of your solution which you're aware of.\n",
    "\n",
    "STEPS\n",
    "- Write a function\n",
    "- Function takes in a list\n",
    "- Reduce the list to 1 entry per company\n",
    "- Consider time complexity\n",
    "- Unit tests prooving it deals with edge cases\n",
    "- Readable and well commented\n",
    "- Share ideas and difficulties\n",
    "- Explain limitations\n",
    "\n",
    "IDEAS\n",
    "Use a set or dictionary to remove duplicates automatically\n",
    "Store the size of the list to compare after cleaning to see how many duplicates were removed\n",
    "Use a decorator to time the function\n",
    "\n",
    "Remove obvious words (without editing them) like 'LIMITED' and 'LTD'\n",
    "Use wildcards to remove the rest\n",
    "Do as few cycles of the list as possible to maintain speed\n",
    "Refactor funtion into smaller functions?\n",
    "Rewrite function timer to take an average of 3\n",
    "\n",
    "QUESTIONS\n",
    "Is transfering to a set less speedy than transfering to a dictionary?\n",
    "Is there a method for removing duplicates? (Pandas? NumPy?)\n",
    "Test a random section instead of the whole document to reduce time?\n",
    "Would a generator be useful?\n",
    "Some of the items are in caps, does case matter?\n",
    "\n",
    "ANSWERS\n",
    "A set is slower than a dictionary\n",
    "Theres an out of data library (precurser to dictionaries) that creates a dictionary. Called collections. This is slower that both sets and dictionaries\n",
    "Numpy has a .unique() method but converting it to an array and back was exceptionally slow\n",
    "Python lists are case sensitive, use lower() to convert all to lowercase. This removed 75 more items but reduced speed by an average of 0.0032\n",
    "\n",
    "\n",
    "RESOURCES USED\n",
    "https://www.w3schools.com/python/python_howto_remove_duplicates.asp\n",
    "https://datagy.io/python-remove-duplicates-from-list/\n",
    "https://www.programiz.com/python-programming/methods/string/casefold"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19d8af6c291ee501da9ca5d95ae68ca5cfdcb85dbde92e8cc63bdd9771af1e34"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
